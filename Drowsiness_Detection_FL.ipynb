{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "25% Complete\n",
      "50% Complete\n",
      "75% Complete\n",
      "Finished Reading data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os \n",
    "\n",
    "file_path = 'C:\\\\Users\\\\Rohith\\\\Documents\\\\Rohith_Stuff\\\\Freelance_stuff\\\\dataset_B_Eye_Images\\\\'\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "print(\"Reading data\")\n",
    "folder = 'closedLeftEyes'\n",
    "data_path = file_path + folder\n",
    "data_path = os.path.join(data_path,'*g')\n",
    "files = glob.glob(data_path)\n",
    "for f1 in files:\n",
    "    img = cv2.imread(f1)\n",
    "    x.append(img)\n",
    "    t = [0,1]          # [open, closed]\n",
    "    y.append(t)\n",
    "print(\"25% Complete\")    \n",
    "folder = 'closedRightEyes'\n",
    "data_path = file_path + folder\n",
    "data_path = os.path.join(data_path,'*g')\n",
    "files = glob.glob(data_path)\n",
    "for f1 in files:\n",
    "    img = cv2.imread(f1)\n",
    "    x.append(img)\n",
    "    t = [0,1]          # [open, closed]\n",
    "    y.append(t)\n",
    "print(\"50% Complete\")    \n",
    "folder = 'openLeftEyes'\n",
    "data_path = file_path + folder\n",
    "data_path = os.path.join(data_path,'*g')\n",
    "files = glob.glob(data_path)\n",
    "for f1 in files:\n",
    "    img = cv2.imread(f1)\n",
    "    x.append(img)\n",
    "    t = [1,0]          # [open, closed]\n",
    "    y.append(t)\n",
    "print(\"75% Complete\")    \n",
    "folder = 'openRightEyes'\n",
    "data_path = file_path + folder\n",
    "data_path = os.path.join(data_path,'*g')\n",
    "files = glob.glob(data_path)\n",
    "for f1 in files:\n",
    "    img = cv2.imread(f1)\n",
    "    x.append(img)\n",
    "    t = [1,0]          # [open, closed]\n",
    "    y.append(t)\n",
    "print(\"Finished Reading data\")    \n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "x,y = shuffle(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(4846):\n",
    "    x_train.append(x[i])\n",
    "    y_train.append(y[i])\n",
    "\n",
    "'''\n",
    "for i in range(3876,4846):\n",
    "    x_test.append(x[i])\n",
    "    y_test.append(y[i])\n",
    "'''    \n",
    "for i in range(len(x_train)//2):\n",
    "    #x_train.append(cv2.flip(x_train[i],0))\n",
    "    x_train.append(cv2.flip(x_train[i],1))\n",
    "    #y_train.append(y_train[i])\n",
    "    y_train.append(y_train[i])\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_train,y_train = shuffle(x_train,y_train)\n",
    "\n",
    "#x_test = np.array(x_test)\n",
    "#y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7269, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohith\\Anaconda3\\envs\\Projects\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 20, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              75501568  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 75,797,282\n",
      "Trainable params: 75,797,026\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7196 samples, validate on 73 samples\n",
      "Epoch 1/10\n",
      "7196/7196 [==============================] - 663s 92ms/step - loss: 0.7055 - acc: 0.7151 - val_loss: 0.6671 - val_acc: 0.6849\n",
      "Epoch 2/10\n",
      "7196/7196 [==============================] - 661s 92ms/step - loss: 0.5100 - acc: 0.7792 - val_loss: 0.5526 - val_acc: 0.8082\n",
      "Epoch 3/10\n",
      "7196/7196 [==============================] - 613s 85ms/step - loss: 0.4457 - acc: 0.7993 - val_loss: 0.4353 - val_acc: 0.8630\n",
      "Epoch 4/10\n",
      "7196/7196 [==============================] - 617s 86ms/step - loss: 0.4196 - acc: 0.8225 - val_loss: 0.3195 - val_acc: 0.8356\n",
      "Epoch 5/10\n",
      "7196/7196 [==============================] - 620s 86ms/step - loss: 0.3772 - acc: 0.8385 - val_loss: 0.2551 - val_acc: 0.8493\n",
      "Epoch 6/10\n",
      "7196/7196 [==============================] - 602s 84ms/step - loss: 0.3670 - acc: 0.8439 - val_loss: 0.3066 - val_acc: 0.8493\n",
      "Epoch 7/10\n",
      "7196/7196 [==============================] - 550s 76ms/step - loss: 0.3738 - acc: 0.8381 - val_loss: 0.3851 - val_acc: 0.8904\n",
      "Epoch 8/10\n",
      "7196/7196 [==============================] - 512s 71ms/step - loss: 0.3645 - acc: 0.8435 - val_loss: 0.3420 - val_acc: 0.8767\n",
      "Epoch 9/10\n",
      "7196/7196 [==============================] - 516s 72ms/step - loss: 0.3495 - acc: 0.8526 - val_loss: 0.3211 - val_acc: 0.8356\n",
      "Epoch 10/10\n",
      "7196/7196 [==============================] - 536s 75ms/step - loss: 0.3378 - acc: 0.8534 - val_loss: 0.2683 - val_acc: 0.8493\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(24,24,3)))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "#model.add(MaxPooling2D((2,2),strides=(2,2)))\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.SGD(lr=0.001),metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train,epochs = 10, verbose = 1, batch_size = 10,validation_split = 0.01)\n",
    "model.save('C:\\\\Users\\\\Rohith\\\\Documents\\\\Rohith_Stuff\\\\Freelance_stuff\\\\drowsy.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohith\\Anaconda3\\envs\\Projects\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('C:\\\\Users\\\\Rohith\\\\Documents\\\\Rohith_Stuff\\\\Freelance_stuff\\\\drowsy.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48052034 0.51947963]\n",
      "[0.6427142  0.35728586]\n",
      "[0.76181483 0.23818517]\n",
      "[0.8337388  0.16626118]\n",
      "[0.64047515 0.35952485]\n",
      "[0.8383667  0.16163328]\n",
      "[0.70635724 0.29364276]\n",
      "[0.4066026 0.5933974]\n",
      "[0.62770534 0.37229466]\n",
      "[0.49748522 0.5025148 ]\n",
      "[0.38962606 0.610374  ]\n",
      "[0.70727265 0.29272735]\n",
      "[0.36549395 0.63450605]\n",
      "[0.4352853  0.56471467]\n",
      "[0.54291695 0.45708305]\n",
      "[0.4730849 0.5269151]\n",
      "[0.52502954 0.47497046]\n",
      "[0.61953485 0.38046512]\n",
      "[0.6253398  0.37466022]\n",
      "[0.36730134 0.63269866]\n",
      "[0.610089   0.38991103]\n",
      "[0.5959703  0.40402976]\n",
      "[0.40649834 0.5935016 ]\n",
      "Warning\n",
      "[0.33535793 0.66464204]\n",
      "[0.2619998 0.7380002]\n",
      "Warning\n",
      "[0.28775212 0.71224785]\n",
      "Warning\n",
      "[0.2557216 0.7442784]\n",
      "Warning\n",
      "[0.5077936  0.49220642]\n",
      "[0.31663397 0.68336606]\n",
      "[0.514768   0.48523203]\n",
      "[0.3882895 0.6117104]\n",
      "Warning\n",
      "[0.67627203 0.32372794]\n",
      "[0.36992773 0.63007224]\n",
      "[0.6623675  0.33763245]\n",
      "[0.36318606 0.636814  ]\n",
      "Warning\n",
      "[0.43254596 0.56745404]\n",
      "[0.704609 0.295391]\n",
      "[0.56691736 0.43308267]\n",
      "[0.3343187 0.6656813]\n",
      "[0.48550802 0.514492  ]\n",
      "[0.34048504 0.65951496]\n",
      "[0.45357668 0.5464233 ]\n",
      "[0.3661562  0.63384384]\n",
      "[0.4448467 0.5551533]\n",
      "[0.32235402 0.677646  ]\n",
      "[0.48108983 0.51891017]\n",
      "[0.31787655 0.6821234 ]\n",
      "[0.56197286 0.43802714]\n",
      "[0.3610482  0.63895184]\n",
      "[0.5666466  0.43335336]\n",
      "[0.29057378 0.7094263 ]\n",
      "[0.43524316 0.56475675]\n",
      "[0.5619947 0.4380054]\n",
      "[0.3561723  0.64382774]\n",
      "[0.33638737 0.66361266]\n",
      "[0.60619265 0.39380738]\n",
      "[0.54346174 0.45653823]\n",
      "[0.34679493 0.65320504]\n",
      "[0.57181257 0.42818737]\n",
      "[0.39735493 0.60264504]\n",
      "[0.7133618  0.28663823]\n",
      "[0.31342053 0.68657947]\n",
      "[0.66183805 0.338162  ]\n",
      "[0.32690004 0.6731    ]\n",
      "[0.7102928  0.28970718]\n",
      "[0.43299997 0.56700003]\n",
      "[0.7876301 0.2123699]\n",
      "[0.43094772 0.5690522 ]\n",
      "[0.688892   0.31110802]\n",
      "[0.35706526 0.6429348 ]\n",
      "[0.7898969 0.2101031]\n",
      "[0.39610735 0.6038927 ]\n",
      "[0.6997021  0.30029792]\n",
      "[0.36934277 0.6306572 ]\n",
      "[0.39041954 0.6095804 ]\n",
      "[0.7024121  0.29758787]\n",
      "[0.6526534  0.34734654]\n",
      "[0.3679068  0.63209325]\n",
      "[0.68645823 0.31354177]\n",
      "[0.3814701 0.6185299]\n",
      "[0.7391598  0.26084024]\n",
      "[0.31683278 0.6831673 ]\n",
      "[0.66947687 0.33052313]\n",
      "[0.30850375 0.69149625]\n",
      "[0.30553937 0.69446063]\n",
      "Warning\n",
      "[0.27789423 0.7221058 ]\n",
      "Warning\n",
      "[0.25989988 0.74010015]\n",
      "Warning\n",
      "[0.3078755  0.69212455]\n",
      "Warning\n",
      "[0.35252303 0.647477  ]\n",
      "Warning\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import winsound\n",
    "\n",
    "duration = 1000  \n",
    "freq = 4450\n",
    "\n",
    "cv2.namedWindow(\"Drowsiness Detection System\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened():\n",
    "    rval, img = vc.read()\n",
    "    #print(rval)\n",
    "else:\n",
    "    rval = False\n",
    "    #print(rval)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('C:\\\\Users\\\\Rohith\\\\Documents\\\\Rohith_Stuff\\\\haar_cascades\\\\haarcascade_frontalface_default.xml')\n",
    "left_eye_cascade_splits = cv2.CascadeClassifier('C:\\\\Users\\\\Rohith\\\\Documents\\\\Rohith_Stuff\\\\haar_cascades\\\\haarcascade_lefteye_2splits.xml')\n",
    "right_eye_cascade_splits = cv2.CascadeClassifier('C:\\\\Users\\\\Rohith\\\\Documents\\\\Rohith_Stuff\\\\haar_cascades\\\\haarcascade_righteye_2splits.xml')\n",
    "\n",
    "\n",
    "while rval:\n",
    "    cv2.imshow(\"Drowsiness Detection System\", img)\n",
    "    rval, frame = vc.read()\n",
    "\n",
    "    img = frame\n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray_img, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = gray_img[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        \n",
    "        warning_1 = warning_2 = 0\n",
    "        #image = roi_color\n",
    "        left_eyes = left_eye_cascade_splits.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in left_eyes:\n",
    "            #cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "            test = roi_color[ey:ey+eh,ex:ex+ew]\n",
    "            test = np.array(test)\n",
    "            #test = np.stack((test,)*3,-1)\n",
    "            image = test\n",
    "            test = cv2.resize(test,(24,24),0,0,cv2.INTER_LINEAR)\n",
    "            test = test.reshape(1,24,24,3)\n",
    "            result = model.predict(test)[0]\n",
    "            #print(result)\n",
    "            warning_1 = np.argmax(result)\n",
    "            #print(warning_1)\n",
    "        right_eyes = right_eye_cascade_splits.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in right_eyes:\n",
    "            #cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "            test = roi_color[ey:ey+eh,ex:ex+ew]\n",
    "            test = np.array(test)\n",
    "            #test = np.stack((test,)*3,-1)\n",
    "            test = cv2.resize(test,(24,24),0,0,cv2.INTER_LINEAR)\n",
    "            test = test.reshape(1,24,24,3)\n",
    "            result = model.predict(test)[0]\n",
    "            warning_2 = np.argmax(result)\n",
    "            #print(warning_2)\n",
    "        \n",
    "        #if(len(left_eyes) > 0 and len(right_eyes) > 0):\n",
    "        if(warning_1 == 1 and warning_2 == 1):\n",
    "            print(\"Warning\")\n",
    "            winsound.Beep(freq, duration)\n",
    "        \n",
    "        '''\n",
    "        test_eyes_l = roi_color[70:135,58:125,:]\n",
    "        test_eyes_l = np.array(test_eyes_l)\n",
    "        test_eyes_l = cv2.resize(test_eyes_l,(24,24),0,0,cv2.INTER_LINEAR)\n",
    "        test_eyes_l = test_eyes_l.reshape(1,24,24,3)\n",
    "        result_l = model.predict(test_eyes_l)[0]\n",
    "        warning_l = np.argmax(result_l)\n",
    "            \n",
    "        test_eyes_r = roi_color[70:135,155:230,:]\n",
    "        test_eyes_r = np.array(test_eyes_r)\n",
    "        test_eyes_r = cv2.resize(test_eyes_r,(24,24),0,0,cv2.INTER_LINEAR)\n",
    "        test_eyes_r = test_eyes_r.reshape(1,24,24,3)\n",
    "        result_r = model.predict(test_eyes_r)[0]\n",
    "        warning_r = np.argmax(result_r)\n",
    "        if(warning_l == 1 or warning_r == 1):\n",
    "            print(\"Warning!!\")\n",
    "            #winsound.Beep(freq, duration)\n",
    "        '''\n",
    "    \n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27: \n",
    "        break\n",
    "cv2.destroyWindow(\"Drowsiness Detection System\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
